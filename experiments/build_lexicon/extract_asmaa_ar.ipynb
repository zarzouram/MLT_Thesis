{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from unicodedata import category, normalize\n",
    "import re\n",
    "import pickle\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Utilities Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_nonspace_mark(x: str) -> bool:\n",
    "    \"\"\"detect diacritics in a string\"\"\"\n",
    "    return bool(category(x) == \"Mn\")\n",
    "\n",
    "\n",
    "def remove_diacritics_ar(text: str) -> str:\n",
    "    \"\"\"remove diacritics in a string\"\"\"\n",
    "    return ''.join([t for t in text if not is_nonspace_mark(t)])\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_text(file):\n",
    "    \"\"\"read file\"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        conllu = f.read()\n",
    "    return conllu\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |     | derived from other word  | word derived from them| Gender |\n",
    " |-----|--------------------------|-----------------------|--------|\n",
    " |جَامِد static |   no              | nothing         | ?M or F or both |\n",
    " |مَصْدَر gerund |   no              | yes             | ?M or F or both |\n",
    " |مُشْتَقّ derived|   yes             | yes             | ?M/F (_nized) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Ism:\n",
    "    \"\"\"This class represents an Arabic noun (ism) and stores information about\n",
    "    its form, lemma, Universal Parts of Speech (upos), root, gender, and\n",
    "    plural. It also includes methods for updating the plural and comparing two\n",
    "    instances of the class, so you can use it as key in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    - form (str): the form of the noun\n",
    "\n",
    "    - lemma (str): the lemma of the noun\n",
    "\n",
    "    - upos (str): the Universal Parts of Speech of the noun\n",
    "\n",
    "    - root (Optional[str]): the root of the noun (default is empty string)\n",
    "\n",
    "    - gender (Optional[str]): the gender of the noun (default is empty string)\n",
    "\n",
    "    - plural (Optional[List[str]]): a list of possible plural forms of the noun\n",
    "      (default is empty list)\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 form: str,\n",
    "                 lemma: str,\n",
    "                 upos: str,\n",
    "                 root: Optional[str] = '',\n",
    "                 gender: Optional[str] = '',\n",
    "                 plural: Optional[List[str]] = '') -> None:\n",
    "        self.form = form\n",
    "        self.lemma = lemma\n",
    "        self.upos = upos\n",
    "        self.root = root\n",
    "        self.gender = gender\n",
    "        self.plural = plural\n",
    "\n",
    "    def update_plural(self, plurals: List[str]):\n",
    "        \"\"\"Updates the plural forms of the noun with the given list of plurals.\n",
    "\n",
    "        Args:\n",
    "            plurals (List[str]): A list of possible plural forms of the noun.\n",
    "        \"\"\"\n",
    "        # get pluras form that are not is self.plural, then update\n",
    "        plurals_new = list(set(plurals) - set(self.plural))\n",
    "        if plurals_new:\n",
    "            self.plural.extend(plurals_new)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Compares two instances of the Ism class for equality based on their\n",
    "        form and lemma.\n",
    "\n",
    "        Args:\n",
    "            other (Ism): The other instance of the Ism class to compare to.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the instances are equal, False otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(other, Ism):\n",
    "            if not (other.form == self.form):\n",
    "                return False\n",
    "\n",
    "            if not (other.lemma == self.lemma):\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                f\"Cannot compare objects of type {type(other).__name__} with {type(self).__name__}\"  # noqa: E501\n",
    "            )\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"Returns a hash value for an instance of the class based on its form\n",
    "        and lemma. Neede if you will use intences of Ism as a dictionary key.\n",
    "\n",
    "        Returns:\n",
    "            int: The hash value for the instance.\n",
    "        \"\"\"\n",
    "        return hash((self.form, self.lemma))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        plurals = \"-\".join(self.plural)\n",
    "        return f'{self.form}[{self.lemma}][ج]({plurals})'\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        plurals = \"-\".join(self.plural)\n",
    "        return f'{self.form}[ج]({plurals})'\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsmDict(dict):\n",
    "    \"\"\"\n",
    "    This class extends the dict class by adding a custom `__setitem__` method\n",
    "    that overrides the default behavior of setting an item in the dictionary.\n",
    "\n",
    "    The original purpose of the `__setitem__` method is to update the\n",
    "    dictionary by adding the value to dictionary according to the key.\n",
    "\n",
    "    However, in this implementation, it first checks whether the key already\n",
    "    exists in the dictionary. The class expects that the key is an instence of\n",
    "    Ism. If the key is already exists, it updates the existing key by merging\n",
    "    its plural with the new key's plural and adds the value to the existing\n",
    "    key's value. If it does not exist, it adds the plural to the dictionary as\n",
    "    is.\n",
    "    \"\"\"\n",
    "\n",
    "    def __setitem__(self, key: Ism, value: list):\n",
    "        if not isinstance(key, Ism):\n",
    "            raise TypeError(\n",
    "                f\"Key must be an instance of Ism, got {type(key).__name__}\")\n",
    "\n",
    "        # Find if key already exists in the dictionary\n",
    "        existing_key = next((k for k in self if k == key), None)\n",
    "        if existing_key is not None:\n",
    "            # If key exists, update its plural and add value to its value\n",
    "            existing_key.update_plural(key.plural)\n",
    "            super().__setitem__(existing_key, self[key] + value)\n",
    "        else:\n",
    "            # If key does not exist, add key-value pair to dictionary\n",
    "            super().__setitem__(key, value)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper CFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_plural(form_plural: str, lemma: str, case: str,\n",
    "                   definite: str) -> Tuple[str, str]:\n",
    "    \"\"\"This function processes the plural form of an Arabic noun and determine\n",
    "    its type. The function uses regular expressions to identify whether the\n",
    "    plural form is a regular plural or a broken plural, and returns an\n",
    "    appropriate response based on the type of plural form.\n",
    "\n",
    "     Args:\n",
    "    - form_plural (str): The plural form of the Arabic noun to be processed.\n",
    "\n",
    "    - lemma (str): The singular form of the Arabic noun.\n",
    "\n",
    "    - case (str): The grammatical case of the noun.\n",
    "\n",
    "    - definite (str): The definiteness of the noun.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "\n",
    "       1. The plural type if detected, either:\n",
    "          - 'broken' for the broken plural\n",
    "          - 'Fem' for the femenine slaem plural\n",
    "          - 'Masc' for masculine salem plural\n",
    "\n",
    "          if there is an error and the plural type is not detectable it return\n",
    "          an error message.\n",
    "\n",
    "       2. The lemma of the noun if the plural type is detected. Otherwise it is\n",
    "           an empty string.\n",
    "    \"\"\"\n",
    "\n",
    "    # remove diacritics\n",
    "    lemma_nodiac = remove_diacritics_ar(lemma)\n",
    "    # sometimes lemma is just one diacritics\n",
    "    if not lemma_nodiac:\n",
    "        print(lemma)\n",
    "\n",
    "    lc = lemma_nodiac[-1]\n",
    "    # regeular exp\n",
    "    definite_regx = re.compile(rf'(ال)?{lemma_nodiac}')\n",
    "    salm_femn_regx = re.compile(rf'(ال)?{lemma_nodiac[:-1]}{lc}?(ات)')\n",
    "    salm_masc_regx = re.compile(rf'(ال)?{lemma_nodiac}(ون|ين|ي|و)')\n",
    "\n",
    "    # common error lemma is the same as plural form\n",
    "    if bool(definite_regx.fullmatch(form_plural)):\n",
    "        return 'wrong_single_form', ''\n",
    "\n",
    "    # should be broken plural if not salem\n",
    "    is_salm_femn_plural = bool(salm_femn_regx.fullmatch(form_plural))\n",
    "    is_salm_masc_plural = bool(salm_masc_regx.fullmatch(form_plural))\n",
    "    is_salm_plural = is_salm_femn_plural or is_salm_masc_plural\n",
    "    if not is_salm_plural:\n",
    "        return 'broken', ''\n",
    "\n",
    "    # TODO - Connected conjunctions and prepositions if not splitted introduce\n",
    "    # an issue when detecting the salem plural. Because the detection is based\n",
    "    # on the lemma, if the lemma is not correct the detection will be wrong.\n",
    "    # جمع مؤنث سالم | Salem feminine plural\n",
    "    if is_salm_femn_plural:\n",
    "        return 'Fem', lemma_nodiac\n",
    "    # جمع مذكر سالم | Salem feminine plural\n",
    "    elif is_salm_masc_plural:\n",
    "        if form_plural.endswith('ي') or form_plural.endswith('و'):\n",
    "            if case == 'Gen' and definite == 'Cons':\n",
    "                return 'Masc', lemma_nodiac\n",
    "            else:\n",
    "                return 'wrong_plural_form', ''\n",
    "        else:\n",
    "            return 'Masc', lemma_nodiac\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_info(conllu: str):\n",
    "    \"\"\"Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "\n",
    "    Args:\n",
    "    - conllu (str): A string containing CoNLL-U formatted data for one or\n",
    "    more sentences.\n",
    "\n",
    "    Returns:\n",
    "        - A tuple containing:\n",
    "          - A list of sentence IDs extracted from the CoNLL-U formatted file.\n",
    "          - A list of sentence texts extracted from the CoNLL-U formatted file.\n",
    "          - A string containing the CoNLL-U formatted data for all sentences\n",
    "          with comments removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "    sent_id_regx = re.compile(r\"(?<=# sent_id = )\\w+\")\n",
    "    text_regex = re.compile(r\"(?<=# text = ).+\")\n",
    "    conllu_filter = re.compile(r\"#.+\\n\")\n",
    "\n",
    "    sent_ids = sent_id_regx.findall(conllu)\n",
    "    texts = text_regex.findall(conllu)\n",
    "    # Remove comments from the CoNLL-U formatted string.\n",
    "    sents_conllu = conllu_filter.sub(repl=\"\", string=conllu)\n",
    "\n",
    "    return sent_ids, texts, sents_conllu\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spaces(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Fix issues with extra spaces in a list of strings.\n",
    "\n",
    "    Args:\n",
    "    - texts (List[str]): A list of strings to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - A list of strings with issues of extra spaces fixed.\"\"\"\n",
    "\n",
    "    # Fix issues with extra spaces in text.\n",
    "    remove_extra_spaces = re.compile(r'\\s\\s+')\n",
    "    add_space_b4r_openbracket = re.compile(r'(?<=\\w)\\(')\n",
    "    add_space_b4r_doublequote = re.compile(r'(?<=\\w)\"')\n",
    "\n",
    "    texts = [remove_extra_spaces.sub(' ', txt) for txt in texts]\n",
    "    texts = [add_space_b4r_openbracket.sub(' (', txt) for txt in texts]\n",
    "    texts = [add_space_b4r_doublequote.sub(' \"', txt) for txt in texts]\n",
    "    texts = [normalize(\"NFKD\", txt) for txt in texts]\n",
    "\n",
    "    return texts\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conllu_sentences(sents_conllu: str):\n",
    "    \"\"\"\n",
    "    Split CoNLL-U formatted data into a list of sentences, each represented as\n",
    "    a list of word/token information.\n",
    "\n",
    "    Args:\n",
    "    - sents_conllu (str): A string containing CoNLL-U formatted data for\n",
    "    one or more sentences.\n",
    "\n",
    "    Returns:\n",
    "    - A list of sentences, each represented as a list of word/token\n",
    "    information. Each word/token information is itself represented as a list of\n",
    "    8 string elements, corresponding to the 8 columns of the CoNLL-U format.\n",
    "    \"\"\"\n",
    "\n",
    "    # This function splits CoNLL-U formatted data into a list of sentences, each\n",
    "    # represented as a list of word/token information. It uses the newline\n",
    "    # character and empty lines to split the input string into separate\n",
    "    # sentences, and then splits each sentence into a list of word/token\n",
    "    # information using tab characters. The function returns a list of these\n",
    "    # sentence lists.\n",
    "\n",
    "    sents_conllu = map(lambda x: x.split(\"\\n\"), sents_conllu.split(\"\\n\\n\"))\n",
    "    sents_conllu = [[tc.split(\"\\t\")[:8] for tc in sc] for sc in sents_conllu]\n",
    "\n",
    "    return sents_conllu\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(feats: str):\n",
    "    \"\"\"Extract morphological features from a string representation of CoNLL-U\n",
    "    formatted word/token features.\n",
    "\n",
    "    Args:\n",
    "    - feats (str): A string containing CoNLL-U formatted word/token features.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        - A string representing the gender of the word/token.\n",
    "        - A string representing the case of the word/token.\n",
    "        - A string representing the definiteness of the word/token.\n",
    "        - A boolean value indicating whether the word/token is plural.\n",
    "\n",
    "    Example usage:\n",
    "    >>> get_feats('Gender=Masc|Number=Sing|Case=Nom')\n",
    "    ('Masc', 'Nom', '', False)\n",
    "        \"\"\"\n",
    "\n",
    "    gender_regex = re.compile(r\"(?<=Gender=)[a-zA-Z]+\")\n",
    "    is_plural_regex = re.compile(r\"Number=Plur\")\n",
    "    definite_regex = re.compile(r\"(?<=Definite=)[a-zA-Z]+\")\n",
    "    case_regex = re.compile(r\"(?<=Case=)[a-zA-Z]+\")\n",
    "\n",
    "    gender = gender_regex.findall(feats)\n",
    "    gender = gender[0] if gender else \"\"\n",
    "\n",
    "    is_plural = bool(is_plural_regex.search(feats))\n",
    "\n",
    "    case_ = case_regex.findall(feats)\n",
    "    case_ = case_[0] if case_ else \"\"\n",
    "\n",
    "    definite = definite_regex.findall(feats)\n",
    "    definite = definite[0] if definite else \"\"\n",
    "\n",
    "    return gender, case_, definite, is_plural\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read Arabic conllu\n",
    "def get_noun_adj_conllu(\n",
    "    conllu_file\n",
    ") -> Tuple[Dict[Ism, Tuple[str, str]], Dict[Ism, Tuple[str, str]], Dict[\n",
    "        Ism, Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Extract information about nouns, adjectives, and X items from a CoNLL-U\n",
    "    formatted file.\n",
    "\n",
    "    Args:\n",
    "    - conllu_file (str): The filepath to the CoNLL-U formatted file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of three dictionaries, containing:\n",
    "        - A dictionary of nouns, where the keys are Ism objects representing\n",
    "          the noun and the values are tuples containing the sentence ID and\n",
    "          text where the noun appears.\n",
    "        - A dictionary of adjectives, where the keys are Ism objects\n",
    "          representing the adjective and the values are tuples containing the\n",
    "          sentence ID and text where the adjective appears.\n",
    "        - A dictionary of X items, where the keys are Ism objects representing\n",
    "          the X item and the values are tuples containing the sentence ID and\n",
    "          text where the X item appears.\n",
    "    \"\"\"\n",
    "\n",
    "    # This function reads a CoNLL-U formatted file and extracts information\n",
    "    # about nouns, adjectives, and X items from the file.\n",
    "\n",
    "    # It uses a variety of helper functions to extract information about each\n",
    "    # token, including its lemma, part of speech, and morphological features.\n",
    "\n",
    "    # It then creates Ism objects to represent each noun, adjective, or X item,\n",
    "    # and stores these objects in one of three dictionaries depending on their\n",
    "    # part of speech. The function returns a tuple containing these three\n",
    "    # dictionaries.\n",
    "\n",
    "    conllu = read_text(conllu_file)  # read CoNLL-U file\n",
    "\n",
    "    # Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "    sent_ids, texts, sents_conllu = extract_sentences_info(conllu)\n",
    "    # Split the CoNLL-U formatted string into sentences and tokens.\n",
    "    sents_conllu = split_conllu_sentences(sents_conllu)\n",
    "    # fix spaces issue with label texts\n",
    "    texts = fix_spaces(texts)\n",
    "\n",
    "    noun_dict = IsmDict()\n",
    "    sus_forms_dict = IsmDict()\n",
    "    x_dict = IsmDict()\n",
    "    adj_dict = IsmDict()\n",
    "    for idx, txt, conllu in zip(sent_ids, texts, sents_conllu):\n",
    "        for token_fields in conllu:\n",
    "            _, form, lemma, upos, _, feats, *_ = token_fields\n",
    "            if upos not in ('NOUN', 'ADJ', 'X'):\n",
    "                continue\n",
    "\n",
    "            # Extract token feats\n",
    "            form_gender, form_case, form_definite, is_plural = get_feats(feats)\n",
    "\n",
    "            # if form is plural according to Conllu feats. Check if the plural\n",
    "            # form is Salem plural. If it is, get the single form. If not, save\n",
    "            # it is the suspected plural dictionary.\n",
    "            if is_plural:\n",
    "                gender_inferred, form_single = process_plural(\n",
    "                    form_plural=form,\n",
    "                    lemma=lemma,\n",
    "                    case=form_case,\n",
    "                    definite=form_definite)\n",
    "                if not form_single:\n",
    "                    form_single = f'X_{form}'\n",
    "                    ism = Ism(form=form_single,\n",
    "                              lemma=lemma,\n",
    "                              upos=upos,\n",
    "                              plural=[],\n",
    "                              gender=form_gender)\n",
    "                    sus_forms_dict[ism] = [(idx, txt)]\n",
    "                else:\n",
    "                    form_gender = gender_inferred\n",
    "                    form_plural = [form]\n",
    "            else:\n",
    "                form_single = form\n",
    "                form_plural = []\n",
    "                form_gender = ''\n",
    "\n",
    "            if upos == 'NOUN':\n",
    "                noun = Ism(form=form_single,\n",
    "                           lemma=lemma,\n",
    "                           upos=upos,\n",
    "                           plural=form_plural,\n",
    "                           gender=form_gender)\n",
    "                noun_dict[noun] = [(idx, txt)]\n",
    "\n",
    "            elif upos == 'ADJ':\n",
    "                adj = Ism(form=form_single,\n",
    "                          lemma=lemma,\n",
    "                          upos=upos,\n",
    "                          plural=form_plural,\n",
    "                          gender=form_gender)\n",
    "                adj_dict[adj] = [(idx, txt)]\n",
    "\n",
    "            elif upos == 'X':\n",
    "                x = Ism(form=form_single,\n",
    "                        lemma=lemma,\n",
    "                        upos=upos,\n",
    "                        plural=form_plural,\n",
    "                        gender=form_gender)\n",
    "                x_dict[x] = [(idx, txt)]\n",
    "\n",
    "    return noun_dict, adj_dict, x_dict, sus_forms_dict\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract information fron Conll-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ar2 = \"../../outputs/conllu/udp_ar edited.conllu\"\n",
    "results_dir = \"../../outputs/conllu_compare/\"\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns, adjs, xs, sus_plurals = get_noun_adj_conllu(file_ar2)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are:\\n - {len(nouns)} nouns\\n - {len(adjs)} adjectives')\n",
    "print(f' - {len(xs)} tokens that cannot be assigned a real UPOS.')\n",
    "print()\n",
    "print(f'There are {len(sus_plurals)} word that could be plural.')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_plurals_counter = 0\n",
    "for token_reper in nouns:\n",
    "    sing_form, plurals = str(token_reper).split('[ج]')\n",
    "\n",
    "    if plurals != '()':\n",
    "        noun_plurals_counter += 1\n",
    "\n",
    "adj_plurals_counter = 0\n",
    "for token_reper in adjs:\n",
    "    sing_form, plurals = str(token_reper).split('[ج]')\n",
    "\n",
    "    if plurals != '()':\n",
    "        adj_plurals_counter += 1\n",
    "\n",
    "x_plurals_counter = 0\n",
    "for token_reper in xs:\n",
    "    sing_form, plurals = str(token_reper).split('[ج]')\n",
    "\n",
    "    if plurals != '()':\n",
    "        x_plurals_counter += 1\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{noun_plurals_counter} plurals are detected in nouns')\n",
    "print(f'{adj_plurals_counter} plurals are detected in adjetives')\n",
    "print(f'{x_plurals_counter} plurals are detected in X')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'{results_dir}{nouns}'\n",
    "with open(f'{file_name}.pkl', \"wb\") as f:\n",
    "    pickle.dump([nouns, adjs, xs, sus_plurals], f)\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}