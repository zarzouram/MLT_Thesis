{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from ism_ar import Ism, IsmDict\n",
    "from utilities import Status\n",
    "\n",
    "from pyarabic import araby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ismdict_path = '../../outputs/lexicons_ar/asmaa.pkl'\n",
    "data_dir = '../../outputs/lexicons_ar/wikitionary_ar/'\n",
    "results_dir = '../../outputs/lexicons_ar/wikitionary_ar/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'{results_dir}nouns_wikitionary'\n",
    "with open(f'{file_name}.pkl', \"rb\") as f:\n",
    "    nouns_wiki = pickle.load(f)\n",
    "\n",
    "file_name = f'{results_dir}adjectives_wikitionary'\n",
    "with open(f'{file_name}.pkl', \"rb\") as f:\n",
    "    adjs_wiki = pickle.load(f)\n",
    "\n",
    "file_name = f'{results_dir}X_wikitionary'\n",
    "with open(f'{file_name}.pkl', \"rb\") as f:\n",
    "    xs_wiki = pickle.load(f)\n",
    "\n",
    "with open(ismdict_path, 'rb') as f:\n",
    "    nouns, adjs, xs, sus_plurals = pickle.load(f)\n",
    "\n",
    "nouns_wiki: List[Tuple[Status, Union[str, None], Ism]]\n",
    "adjs_wiki: List[Tuple[Status, Union[str, None], Ism]]\n",
    "xs_wiki: List[Tuple[Status, Union[str, None], Ism]]\n",
    "nouns: IsmDict\n",
    "adjs: IsmDict\n",
    "xs: IsmDict\n",
    "sus_plurals: IsmDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_section_regex = re.compile(\n",
    "    r'''(?:                      # positive lookbehind assertions\n",
    "            (?<=====Noun====\\n)  # Start looking for third or forth level\n",
    "            |                    # section headers that are used to identify\n",
    "            (?<====Noun===\\n)    # noun sections in the wikitext\n",
    "        )\n",
    "        .+?                      # Match any chars non-greedily from then until\n",
    "        (?=(\\n?===\\w+===\\n)      # positive lookahead assertion\n",
    "            |                    # mathes either the next section header\n",
    "        <<END>>\\n)               # or end of the file.\n",
    "    ''',\n",
    "    flags=re.S | re.VERBOSE)\n",
    "\n",
    "adj_section_re = re.compile(\n",
    "    r'''(?:                           # positive lookbehind assertions\n",
    "            (?<=====Adjective====\\n)  # Start looking for third or forth level\n",
    "            |                         # section headers that are used to\n",
    "            (?<====Adjective===\\n)    # identify adj sections in the wikitext\n",
    "        )\n",
    "        .+?                      # Match any chars non-greedily from then until\n",
    "        (?=(\\n?===\\w+===\\n)      # positive lookahead assertion\n",
    "            |                    # mathes either the next section header\n",
    "        <<END>>\\n)               # or end of the file.\n",
    "    ''',\n",
    "    flags=re.S | re.VERBOSE)\n",
    "\n",
    "noun_template_re = re.compile(r'{{ar-noun\\|.+?}}')\n",
    "noun_dec_template_re = re.compile(\n",
    "    r'{{ar-decl-(gendered-)?(coll-)?(sing-)?noun\\|.+?}}')\n",
    "noun_plural_re = re.compile('{{ar-noun-(pl|dual)\\|.+?}}')\n",
    "\n",
    "adj_template_re = re.compile(r'{{ar-(adj|adjective)\\|.+?}}')\n",
    "adj_dec_template_re = re.compile(r'{{ar-decl-adj\\|.+?}}')\n",
    "adj_plural_re = re.compile('{{ar-adj-pl\\|.+?}}')\n",
    "adj_fem_re = re.compile(r'{{ar-adj-fem\\|.+?}}')\n",
    "\n",
    "lemma_temp_re = re.compile(r'(?<=\\|)[\\u0600-\\u06FF]+')\n",
    "gender_temp_re = re.compile(r'(?<=\\|)(m|f)(?=\\||}})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS extracted from Wikitext\n",
      "================================================\n",
      "Noun Found:                      1441\n",
      "Adjectives Found:                38\n",
      "Neither noun nor Adjectives:     628\n",
      "total Nouns as shown in Conll-u: 2107\n",
      "\n",
      "Discrepancies in features between Wikitext and Conll-U\n",
      "======================================================\n",
      "Differences in lemma:  178\n",
      "Differences in gender: 32\n"
     ]
    }
   ],
   "source": [
    "# https://regex101.com/r/OOfoB2/1\n",
    "count_adj = 0\n",
    "count_noun = 0\n",
    "count_not_ism = 0\n",
    "count_lemma_diff = 0\n",
    "count_gender_diff = 0\n",
    "\n",
    "for status, wikitext, ism in nouns_wiki:\n",
    "    if status == Status.EntryFound:\n",
    "        wikitext_ = wikitext + '\\n<<END>>\\n'  # append end mark to wikitext\n",
    "        # get the noun section in wikitext. If not found get the adjective\n",
    "        # section\n",
    "        if noun_section := noun_section_regex.search(wikitext_):\n",
    "            count_noun += 1\n",
    "            noun_section = noun_section.group()\n",
    "            # There multiple tempelates in the noun section. get one\n",
    "            # template if not found get for the net one.\n",
    "            # 1. Noun template: {{ar-noun| }} template\n",
    "            if noun_template := noun_template_re.search(noun_section):\n",
    "                noun_template = noun_template.group()\n",
    "\n",
    "                lemma_wiki = lemma_temp_re.search(noun_template).group()\n",
    "                if not araby.vocalizedlike(lemma_wiki, ism.lemma):\n",
    "                    count_lemma_diff += 1\n",
    "\n",
    "                gender_wiki = gender_temp_re.search(noun_template)\n",
    "                if not bool(gender_wiki):\n",
    "                    if '{{ar-noun|تِقَانَة}}' == noun_template:\n",
    "                        pass\n",
    "                if ism.gender:\n",
    "                    gender_wiki = gender_wiki.group()\n",
    "                    if ism.gender[0].lower() != gender_wiki:\n",
    "                        count_gender_diff += 1\n",
    "\n",
    "                # ism.gender = gender_wiki if not ism.gender\n",
    "\n",
    "            # 2. Noun declension template {{ar-noun| }} template\n",
    "            elif noun_template := noun_dec_template_re.search(noun_section):\n",
    "                pass\n",
    "\n",
    "            # 3. Neither noun nor noun declension template are found. See if\n",
    "            #    the noun is pluaral. i.e. feat is wrong in Conll-U.\n",
    "            elif noun_plural := noun_plural_re.search(noun_section):\n",
    "                pass\n",
    "\n",
    "            # No templates are found in noun section!\n",
    "            else:\n",
    "                pass\n",
    "        elif adj_section := adj_section_re.search(wikitext_):\n",
    "            count_adj += 1\n",
    "            adj_section = adj_section.group()\n",
    "            # There multiple tempelates in the adjective section. get one\n",
    "            # template if not found get for the net one.\n",
    "            # 1. Adj template: {{ar-adj| }} or {{ar-adjectives| }} template\n",
    "            if adj_template := adj_template_re.search(adj_section):\n",
    "                adj_template = adj_template.group()\n",
    "\n",
    "                # Two adjectives does not have an Arabic lemma\n",
    "                lemma_wiki = lemma_temp_re.search(adj_template)\n",
    "                if bool(lemma_wiki):\n",
    "                    lemma_wiki = lemma_wiki.group()\n",
    "                    if not araby.vocalizedlike(lemma_wiki, ism.lemma):\n",
    "                        count_lemma_diff += 1\n",
    "\n",
    "                # gender_wiki = gender_temp_re.search(noun_template)\n",
    "                # if not bool(gender_wiki):\n",
    "                #     if '{{ar-noun|تِقَانَة}}' == noun_template:\n",
    "                #         pass\n",
    "                # if ism.gender:\n",
    "                #     gender_wiki = gender_wiki.group()\n",
    "                #     if ism.gender[0].lower() != gender_wiki:\n",
    "                #         count_gender_diff += 1\n",
    "\n",
    "            elif adj_template := adj_dec_template_re.search(adj_section):\n",
    "                pass\n",
    "            elif adj_plural := adj_plural_re.search(adj_section):\n",
    "                pass\n",
    "            elif adj_fem := adj_fem_re.search(adj_section):\n",
    "                pass\n",
    "                # go to the {{feminine singular of|ar|مُتَعَدِّد}\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            count_not_ism += 1\n",
    "\n",
    "total_records = count_noun + count_adj + count_not_ism\n",
    "print('POS extracted from Wikitext')\n",
    "print('================================================')\n",
    "print(f'Noun Found:                      {count_noun}')\n",
    "print(f'Adjectives Found:                {count_adj}')\n",
    "print(f'Neither noun nor Adjectives:     {count_not_ism}')\n",
    "print(f'total Nouns as shown in Conll-u: {total_records}')\n",
    "print()\n",
    "print('Discrepancies in features between Wikitext and Conll-U')\n",
    "print('======================================================')\n",
    "print(f'Differences in lemma:  {count_lemma_diff}')\n",
    "print(f'Differences in gender: {count_gender_diff}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{ar-adj|سَرِيع|f=سَرِيعَة|cpl=سِرَاع|pl=سَرِيعُونَ|pl2=سُرْعَان|fpl=سَرِيعَات|el=أَسْرَع}}\n",
      "\n",
      "# [[fast]] {{gloss|capable of moving with speed}}, [[quick]] {{gloss|moving with speed}}\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|سَرِيع|f=سَرِيعَة|cpl=سِرَاع|pl=smp|pl2=سُرْعَان|fpl=sfp}}\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-adj-fem|رَسْمِيَّة}}\n",
      "\n",
      "# {{feminine singular of|ar|رَسْمِيّ}}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-nisba|رِيَاضِيّ}}\n",
      "# of or [[pertain]]ing to [[sport]]s\n",
      "#: {{l|ar|[[أَلْعَاب]] [[رِيَاضِيَّة]]|t=sports}}\n",
      "#: {{l|ar|[[أَخْبَار]] [[رِيَاضِيَّة]]|t=sports news}}\n",
      "#: {{l|ar|[[مُرَاسِل]] [[رِيَاضِيّ]]|t=sports reporter}}\n",
      "## [[sportsmanly]]; [[sportsmanlike]]\n",
      "##: {{l|ar|[[رُوح]] [[رِيَاضِيّة]]|t=a sportsmanly spirit}}\n",
      "# of or [[pertain]]ing to [[physical]] [[sport]]s or [[athletics]]\n",
      "## [[resemblant]] of [[athlete]]s, [[athletic]]\n",
      "##: {{l|ar|[[نَمَط]] [[رِيَاضِيّ]]|t=an athletic type}}\n",
      "##: {{l|ar|[[جَسَد]] [[رِيَاضِيّ]]|t=an athletic body}}\n",
      "# [[mathematic]], [[mathematical]]\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|رِيَاضِيّ|pl=smp}}\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-nisba|فَلَكِيّ}}\n",
      "\n",
      "# [[astronomic]], [[astronomical]]\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|فَلَكِيّ|pl=sp}}\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-adj-sound|وَاضِع}}\n",
      "\n",
      "# {{active participle of|ar|وَضَعَ}}\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|وَاضِع|pl=sp}}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-nisba|رَئِيسِيّ}}\n",
      "\n",
      "# [[main]], [[chief]], [[principal]], [[leading]], [[cardinal]]\n",
      "#:* {{uxi|ar|[[الفَضَائِل الرَئِيسِيَّة]]|[[cardinal virtues]]}}\n",
      "#:* {{uxi|ar|مَقَالَة رَئِيسِيَّة|lead article, editorial}}\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|رَئِيسِيّ|pl=sp}}\n",
      "\n",
      "==South Levantine Arabic==\n",
      "{{ajp-root|ر ء س}}\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-adj|نَبِيل|f=نَبِيلَة|pl=نُبَلَاء|fpl=نَبِيلَات|fpl2=نَبَائِل|el=أَنْبَل}}\n",
      "\n",
      "# [[noble]], of [[noble]] [[lineage]], [[honored]], [[celebrated]]\n",
      "# [[excellent]], [[eminent]]\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|نَبِيل|f=نَبِيلَة|pl=نُبَلَاء|fpl=نَبِيلَات|fpl2=نَبَائِل|el=أَنْبَل}}\n",
      "\n",
      "=\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-nisba|سِيَاسِيّ}}\n",
      "\n",
      "# [[political]] {{c|ar|Politics}}\n",
      "# [[diplomatic]]\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|سِيَاسِيّ|pl=sp}}\n",
      "\n",
      "==\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-adj-fem|جَوِّيَّة}}\n",
      "\n",
      "# {{feminine singular of|ar|جَوِّيّ}}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "{{ar-nisba|كِيمِيَائِيّ}}\n",
      "\n",
      "# [[chemical]]\n",
      "\n",
      "====Declension====\n",
      "{{ar-decl-adj|كِيمِيَائِيّ|pl=sp}}\n",
      "\n",
      "====References====\n",
      "* {{R:ar:Wehr-4|كيمياء}}\n",
      "\n",
      "---------------------------------------------\n",
      "10 1 3\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "count_adj = 0\n",
    "count_noun = 0\n",
    "count = 0\n",
    "count_break = 0\n",
    "for status, wikitext, ism in adjs_wiki:\n",
    "    if status == Status.EntryFound:\n",
    "        wikitext_ = wikitext + '\\n<<END>>\\n'\n",
    "        if bool(adj_section_re.search(wikitext_)):\n",
    "            count_noun += 1\n",
    "            print(adj_section_re.search(wikitext_).group())\n",
    "            print(\"---------------------------------------------\")\n",
    "            count_break += 1\n",
    "            if count_break == 10:\n",
    "                break\n",
    "        elif bool(noun_section_regex.search(wikitext_)):\n",
    "            count_adj += 1\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "print(count_noun, count_adj, count)\n",
    "print(count_noun + count_adj + count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 33 374\n",
      "661\n"
     ]
    }
   ],
   "source": [
    "count_adj = 0\n",
    "count_noun = 0\n",
    "count = 0\n",
    "for status, wikitext, ism in xs_wiki:\n",
    "    if status == Status.EntryFound:\n",
    "        wikitext_ = wikitext + '\\n<<END>>\\n'\n",
    "        if bool(noun_section_regex.search(wikitext_)):\n",
    "            count_noun += 1\n",
    "        elif bool(adj_section_re.search(wikitext_)):\n",
    "            count_adj += 1\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "print(count_noun, count_adj, count)\n",
    "print(count_noun + count_adj + count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ```python\n",
    "   n = samplesize_confint_proportion(0.5, 0.05, 0.1)\n",
    "   sample_size = ceil(n / (1 + ((n - 1) / len(statuses\n",
    "   notfound_nouns = [\n",
    "       noun for status, _, noun in zip(statuses, parsed, isms)\n",
    "       if status == Status.EntryNotFound\n",
    "   ]\n",
    "   random_notfound_nouns = random.sample(notfound_nouns, sample_s\n",
    "   notfound_info = ''\n",
    "   for notfound_noun in notfound_nouns:\n",
    "       idx, label = nouns[notfound_noun][0]\n",
    "       notfound_info += f'{idx}\\t[{label}]\\t{notfound_noun.form}\\t'\n",
    "       notfound_info += f'{notfound_noun.lemma\n",
    "   file_name = f'{results_dir}nouns_notfound.txt'\n",
    "   with open(file_name, 'w') as f:\n",
    "       f.write(notfound_info)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " {{ar-noun|رَئِيس|m|pl=رُؤَسَاء|f=رَئِيسَة}}\n",
    " {{ar-noun|طَرِيق|m|g2=f|pl=طُرُق|pl2=طُرُقَات}}\n",
    " {{ar-noun|حُكُومَة|f|pl=حُكُومَات}}\n",
    " {{ar-noun|لَافِتَة|f|pl=لَافِتَات}}\n",
    " {{ar-noun|خَرِيطَة|f|pl=خَرَائِط}}\n",
    " ====Declension====\n",
    " {{ar-decl-gendered-noun|رَئِيس|pl=رُؤَسَاء}}\n",
    " {{ar-decl-noun|حُكُومَة|pl=حُكُومَات}}\n",
    " {{ar-decl-noun|لَافِتَة|pl=sfp}}\n",
    " {{ar-decl-noun|طَرِيق|pl=طُرُق|pl2=طُرُقَات}}\n",
    " {{ar-decl-noun|خَرِيطَة|pl=خَرَائِط}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thss-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
