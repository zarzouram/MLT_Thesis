{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from unicodedata import category, normalize\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from ism_ar import Ism, IsmDict\n",
    "from utilities import remove_diacritics_ar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Utilities Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file):\n",
    "    \"\"\"read file\"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        conllu = f.read()\n",
    "    return conllu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_plural(form_plural: str, lemma: str, case: str,\n",
    "                   definite: str) -> Tuple[str, str]:\n",
    "    \"\"\"This function processes the plural form of an Arabic noun and determine\n",
    "    its type. The function uses regular expressions to identify whether the\n",
    "    plural form is a regular plural or a broken plural, and returns an\n",
    "    appropriate response based on the type of plural form.\n",
    "\n",
    "     Args:\n",
    "    - form_plural (str): The plural form of the Arabic noun to be processed.\n",
    "\n",
    "    - lemma (str): The singular form of the Arabic noun.\n",
    "\n",
    "    - case (str): The grammatical case of the noun.\n",
    "\n",
    "    - definite (str): The definiteness of the noun.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "\n",
    "       1. The plural type if detected, either:\n",
    "          - 'broken' for the broken plural\n",
    "          - 'Fem' for the femenine slaem plural\n",
    "          - 'Masc' for masculine salem plural\n",
    "\n",
    "          if there is an error and the plural type is not detectable it return\n",
    "          an error message.\n",
    "\n",
    "       2. The lemma of the noun if the plural type is detected. Otherwise it is\n",
    "           an empty string.\n",
    "    \"\"\"\n",
    "\n",
    "    # remove diacritics\n",
    "    lemma_nodiac = remove_diacritics_ar(lemma)\n",
    "\n",
    "    lc = lemma_nodiac[-1]\n",
    "    # regeular exp\n",
    "    definite_regx = re.compile(rf'(ال)?{lemma_nodiac}')\n",
    "    salm_femn_regx = re.compile(rf'(ال)?{lemma_nodiac[:-1]}{lc}?(ات)')\n",
    "    salm_masc_regx = re.compile(rf'(ال)?{lemma_nodiac}(ون|ين|ي|و)')\n",
    "\n",
    "    # common error lemma is the same as plural form\n",
    "    if bool(definite_regx.fullmatch(form_plural)):\n",
    "        return 'wrong_single_form', ''\n",
    "\n",
    "    # should be broken plural if not salem\n",
    "    is_salm_femn_plural = bool(salm_femn_regx.fullmatch(form_plural))\n",
    "    is_salm_masc_plural = bool(salm_masc_regx.fullmatch(form_plural))\n",
    "    is_salm_plural = is_salm_femn_plural or is_salm_masc_plural\n",
    "    if not is_salm_plural:\n",
    "        return 'broken', ''\n",
    "\n",
    "    # TODO - Connected conjunctions and prepositions if not splitted introduce\n",
    "    # an issue when detecting the salem plural. Because the detection is based\n",
    "    # on the lemma, if the lemma is not correct the detection will be wrong.\n",
    "    # جمع مؤنث سالم | Salem feminine plural\n",
    "    if is_salm_femn_plural:\n",
    "        return 'Fem', lemma_nodiac\n",
    "    # جمع مذكر سالم | Salem feminine plural\n",
    "    elif is_salm_masc_plural:\n",
    "        if form_plural.endswith('ي') or form_plural.endswith('و'):\n",
    "            if case == 'Gen' and definite == 'Cons':\n",
    "                return 'Masc', lemma_nodiac\n",
    "            else:\n",
    "                return 'wrong_plural_form', ''\n",
    "        else:\n",
    "            return 'Masc', lemma_nodiac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_info(conllu: str):\n",
    "    \"\"\"Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "\n",
    "    Args:\n",
    "    - conllu (str): A string containing CoNLL-U formatted data for one or\n",
    "    more sentences.\n",
    "\n",
    "    Returns:\n",
    "        - A tuple containing:\n",
    "          - A list of sentence IDs extracted from the CoNLL-U formatted file.\n",
    "          - A list of sentence texts extracted from the CoNLL-U formatted file.\n",
    "          - A string containing the CoNLL-U formatted data for all sentences\n",
    "          with comments removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "    sent_id_regx = re.compile(r\"(?<=# sent_id = )\\w+\")\n",
    "    text_regex = re.compile(r\"(?<=# text = ).+\")\n",
    "    conllu_filter = re.compile(r\"#.+\\n\")\n",
    "\n",
    "    sent_ids = sent_id_regx.findall(conllu)\n",
    "    texts = text_regex.findall(conllu)\n",
    "    # Remove comments from the CoNLL-U formatted string.\n",
    "    sents_conllu = conllu_filter.sub(repl=\"\", string=conllu)\n",
    "\n",
    "    return sent_ids, texts, sents_conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spaces(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Fix issues with extra spaces in a list of strings.\n",
    "\n",
    "    Args:\n",
    "    - texts (List[str]): A list of strings to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - A list of strings with issues of extra spaces fixed.\"\"\"\n",
    "\n",
    "    # Fix issues with extra spaces in text.\n",
    "    remove_extra_spaces = re.compile(r'\\s\\s+')\n",
    "    add_space_b4r_openbracket = re.compile(r'(?<=\\w)\\(')\n",
    "    add_space_b4r_doublequote = re.compile(r'(?<=\\w)\"')\n",
    "\n",
    "    texts = [remove_extra_spaces.sub(' ', txt) for txt in texts]\n",
    "    texts = [add_space_b4r_openbracket.sub(' (', txt) for txt in texts]\n",
    "    texts = [add_space_b4r_doublequote.sub(' \"', txt) for txt in texts]\n",
    "    texts = [normalize(\"NFKD\", txt) for txt in texts]\n",
    "\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conllu_sentences(sents_conllu: str):\n",
    "    \"\"\"\n",
    "    Split CoNLL-U formatted data into a list of sentences, each represented as\n",
    "    a list of word/token information.\n",
    "\n",
    "    Args:\n",
    "    - sents_conllu (str): A string containing CoNLL-U formatted data for\n",
    "    one or more sentences.\n",
    "\n",
    "    Returns:\n",
    "    - A list of sentences, each represented as a list of word/token\n",
    "    information. Each word/token information is itself represented as a list of\n",
    "    8 string elements, corresponding to the 8 columns of the CoNLL-U format.\n",
    "    \"\"\"\n",
    "\n",
    "    # This function splits CoNLL-U formatted data into a list of sentences, each\n",
    "    # represented as a list of word/token information. It uses the newline\n",
    "    # character and empty lines to split the input string into separate\n",
    "    # sentences, and then splits each sentence into a list of word/token\n",
    "    # information using tab characters. The function returns a list of these\n",
    "    # sentence lists.\n",
    "\n",
    "    sents_conllu = map(lambda x: x.split(\"\\n\"), sents_conllu.split(\"\\n\\n\"))\n",
    "    sents_conllu = [[tc.split(\"\\t\")[:8] for tc in sc] for sc in sents_conllu]\n",
    "\n",
    "    return sents_conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(feats: str) -> Tuple[str, str, str, bool]:\n",
    "    \"\"\"Extract morphological features from a string representation of CoNLL-U\n",
    "    formatted word/token features.\n",
    "\n",
    "    Args:\n",
    "    - feats (str): A string containing CoNLL-U formatted word/token features.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        - A string representing the gender of the word/token.\n",
    "        - A string representing the case of the word/token.\n",
    "        - A string representing the definiteness of the word/token.\n",
    "        - A boolean value indicating whether the word/token is plural.\n",
    "\n",
    "    Example usage:\n",
    "    >>> get_feats('Gender=Masc|Number=Sing|Case=Nom')\n",
    "    ('Masc', 'Nom', '', False)\n",
    "        \"\"\"\n",
    "\n",
    "    gender_regex = re.compile(r\"(?<=Gender=)[a-zA-Z]+\")\n",
    "    is_plural_regex = re.compile(r\"Number=Plur\")\n",
    "    definite_regex = re.compile(r\"(?<=Definite=)[a-zA-Z]+\")\n",
    "    case_regex = re.compile(r\"(?<=Case=)[a-zA-Z]+\")\n",
    "\n",
    "    gender = gender_regex.findall(feats)\n",
    "    gender = gender[0] if gender else \"\"\n",
    "\n",
    "    is_plural = bool(is_plural_regex.search(feats))\n",
    "\n",
    "    case_ = case_regex.findall(feats)\n",
    "    case_ = case_[0] if case_ else \"\"\n",
    "\n",
    "    definite = definite_regex.findall(feats)\n",
    "    definite = definite[0] if definite else \"\"\n",
    "\n",
    "    return gender, case_, definite, is_plural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Arabic conllu\n",
    "def get_noun_adj_conllu(\n",
    "    conllu_file\n",
    ") -> Tuple[Dict[Ism, Tuple[str, str]], Dict[Ism, Tuple[str, str]], Dict[\n",
    "        Ism, Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Extract information about nouns, adjectives, and X items from a CoNLL-U\n",
    "    formatted file.\n",
    "\n",
    "    Args:\n",
    "    - conllu_file (str): The filepath to the CoNLL-U formatted file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of three dictionaries, containing:\n",
    "        - A dictionary of nouns, where the keys are Ism objects representing\n",
    "          the noun and the values are tuples containing the sentence ID and\n",
    "          text where the noun appears.\n",
    "        - A dictionary of adjectives, where the keys are Ism objects\n",
    "          representing the adjective and the values are tuples containing the\n",
    "          sentence ID and text where the adjective appears.\n",
    "        - A dictionary of X items, where the keys are Ism objects representing\n",
    "          the X item and the values are tuples containing the sentence ID and\n",
    "          text where the X item appears.\n",
    "    \"\"\"\n",
    "\n",
    "    is_arabic_regex = re.compile(r'[\\u0600-\\u06FF]+')\n",
    "\n",
    "    # This function reads a CoNLL-U formatted file and extracts information\n",
    "    # about nouns, adjectives, and X items from the file.\n",
    "\n",
    "    # It uses a variety of helper functions to extract information about each\n",
    "    # token, including its lemma, part of speech, and morphological features.\n",
    "\n",
    "    # It then creates Ism objects to represent each noun, adjective, or X item,\n",
    "    # and stores these objects in one of three dictionaries depending on their\n",
    "    # part of speech. The function returns a tuple containing these three\n",
    "    # dictionaries.\n",
    "\n",
    "    conllu = read_text(conllu_file)  # read CoNLL-U file\n",
    "\n",
    "    # Extract sentence IDs and text from the CoNLL-U formatted file.\n",
    "    sent_ids, texts, sents_conllu = extract_sentences_info(conllu)\n",
    "    # Split the CoNLL-U formatted string into sentences and tokens.\n",
    "    sents_conllu = split_conllu_sentences(sents_conllu)\n",
    "    # fix spaces issue with label texts\n",
    "    texts = fix_spaces(texts)\n",
    "\n",
    "    noun_dict = IsmDict()\n",
    "    sus_forms_dict = IsmDict()\n",
    "    x_dict = IsmDict()\n",
    "    adj_dict = IsmDict()\n",
    "    for idx, txt, conllu in zip(sent_ids, texts, sents_conllu):\n",
    "        for token_fields in conllu:\n",
    "            _, form, lemma, upos, _, feats, *_ = token_fields\n",
    "\n",
    "            if upos not in ('NOUN', 'ADJ', 'X'):\n",
    "                continue\n",
    "            if not bool(is_arabic_regex.match(form)):\n",
    "                continue\n",
    "\n",
    "            # Extract token feats\n",
    "            form_gender, form_case, form_definite, is_plural = get_feats(feats)\n",
    "\n",
    "            # if form is plural according to Conllu feats. Check if the plural\n",
    "            # form is Salem plural. If it is, get the single form. If not, save\n",
    "            # it is the suspected plural dictionary.\n",
    "            if is_plural:\n",
    "                gender_inferred, form_single = process_plural(\n",
    "                    form_plural=form,\n",
    "                    lemma=lemma,\n",
    "                    case=form_case,\n",
    "                    definite=form_definite)\n",
    "                if not form_single:\n",
    "                    ism = Ism(form=form,\n",
    "                              lemma=lemma,\n",
    "                              upos=upos,\n",
    "                              gender=form_gender)\n",
    "                    sus_forms_dict[ism] = [(idx, txt)]\n",
    "                    continue\n",
    "                else:\n",
    "                    # Salem Plural\n",
    "                    form_gender = gender_inferred\n",
    "                    has_salem_pl = True\n",
    "\n",
    "            # singular word\n",
    "            else:\n",
    "                form_single = form\n",
    "                has_salem_pl = None\n",
    "\n",
    "            if upos == 'NOUN':\n",
    "                noun = Ism(form=form_single,\n",
    "                           lemma=lemma,\n",
    "                           upos=upos,\n",
    "                           has_salem_pl=has_salem_pl,\n",
    "                           gender=form_gender)\n",
    "                noun_dict[noun] = [(idx, txt)]\n",
    "\n",
    "            elif upos == 'ADJ':\n",
    "                adj = Ism(form=form_single,\n",
    "                          lemma=lemma,\n",
    "                          upos=upos,\n",
    "                          has_salem_pl=has_salem_pl,\n",
    "                          gender=form_gender)\n",
    "                adj_dict[adj] = [(idx, txt)]\n",
    "\n",
    "            elif upos == 'X':\n",
    "                x = Ism(form=form_single,\n",
    "                        lemma=lemma,\n",
    "                        upos=upos,\n",
    "                        has_salem_pl=has_salem_pl,\n",
    "                        gender=form_gender)\n",
    "                x_dict[x] = [(idx, txt)]\n",
    "\n",
    "    return noun_dict, adj_dict, x_dict, sus_forms_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract information fron Conll-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ar2 = \"../../outputs/conllu/wikibase-item_quantity_time/udp_ar.conllu\"\n",
    "results_dir = \"../../outputs/lexicons_ar/wikibase-item_quantity_time/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns, adjs, xs, sus_plurals = get_noun_adj_conllu(file_ar2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:\n",
      " - 1328 nouns\n",
      " - 566 adjectives\n",
      " - 305 tokens that cannot be assigned a real UPOS.\n",
      "\n",
      "There are 169 word that could be plural.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are:\\n - {len(nouns)} nouns\\n - {len(adjs)} adjectives')\n",
    "print(f' - {len(xs)} tokens that cannot be assigned a real UPOS.')\n",
    "print()\n",
    "print(f'There are {len(sus_plurals)} word that could be plural.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking for Arabic charchters, number words with 'X' POS reduced from `3665`\n",
    "to `2953 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_plurals_counter = 0\n",
    "for noun in nouns:\n",
    "    if noun.has_salem_pl:\n",
    "        noun_plurals_counter += 1\n",
    "\n",
    "adj_plurals_counter = 0\n",
    "for adj in adjs:\n",
    "    if adj.has_salem_pl:\n",
    "        adj_plurals_counter += 1\n",
    "\n",
    "x_plurals_counter = 0\n",
    "for x in xs:\n",
    "    if x.has_salem_pl:\n",
    "        x_plurals_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 plurals are detected in nouns\n",
      "13 plurals are detected in adjetives\n",
      "0 plurals are detected in X\n"
     ]
    }
   ],
   "source": [
    "print(f'{noun_plurals_counter} plurals are detected in nouns')\n",
    "print(f'{adj_plurals_counter} plurals are detected in adjetives')\n",
    "print(f'{x_plurals_counter} plurals are detected in X')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'{results_dir}asmaa'\n",
    "with open(f'{file_name}.pkl', \"wb\") as f:\n",
    "    pickle.dump([nouns, adjs, xs, sus_plurals], f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thss-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
