{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_words_gf = Path(\"../data/wikimini/Words.gf\")\n",
    "path_ar_tsv = Path(\"../data/raw/arabic.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neglect = set([\"PN\", \"LN\", \"SN\", \"GN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_vs_gf_ar(\n",
    "    tsv_path: Path, gf_path: Path, pos_neglect: set = set()\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compares TSV file with GF file and extracts records present in both.\n",
    "\n",
    "    This function reads records from a TSV file and checks for their presence in a GF file.  Only records that are found in both\n",
    "    files, and are not part of the pos_neglect set, are retained.  The results are returned as a Pandas DataFrame with columns:\n",
    "    'ar', 'en', and an index 'li' which is the line number of the TSV file.\n",
    "\n",
    "    Args:\n",
    "        tsv_path (Path): The path to the TSV file that contains the records to be checked.  \n",
    "        gf_path (Path): The path to the GF file which serves as a reference for comparison.  \n",
    "        pos_neglect (set, optional): Set of POS (parts-of-speech) tags to be neglected when comparing records. Defaults to an\n",
    "        empty set.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing records ('ar', 'en') that are present in both the TSV and GF files.  The dataframe\n",
    "        is indexed by 'li', which represents the line number in the original TSV file.\n",
    "    \"\"\"\n",
    "    dict_tsv = {\"ar\": [], \"en\": [], \"li\": []}\n",
    "\n",
    "    # Read files, fg and tsv\n",
    "    with open(tsv_path) as tsv_obj:\n",
    "        list_tsv = tsv_obj.readlines()\n",
    "    with open(gf_path) as gf_obj:\n",
    "        set_gf = set(map(lambda x: x.strip()[:-1], gf_obj.readlines()[2:-1]))\n",
    "\n",
    "    # save records that are found in both gf and tsv\n",
    "    for i, line_tsv in enumerate(list_tsv):\n",
    "        en_token, _, ar_words, _ = line_tsv.split(\"\\t\")\n",
    "        _, pos = en_token.rsplit(\"_\", 1)\n",
    "        if (pos in pos_neglect) or (not en_token in set_gf):\n",
    "            continue\n",
    "\n",
    "        dict_tsv[\"en\"].append(en_token)\n",
    "        dict_tsv[\"ar\"].append(ar_words)\n",
    "        dict_tsv[\"li\"].append(i)\n",
    "\n",
    "    return pd.DataFrame(dict_tsv).set_index(\"li\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_en_words = tsv_vs_gf_ar(path_ar_tsv, path_words_gf, pos_neglect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ar</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>مطلق</td>\n",
       "      <td>absolute_3_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>إِدارِيّ</td>\n",
       "      <td>administrative_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>أفْغانِيّ</td>\n",
       "      <td>afghani_1_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>لغة أفريكانية</td>\n",
       "      <td>afrikaans_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>سِنّ</td>\n",
       "      <td>age_1_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>الأكانية</td>\n",
       "      <td>akan_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>ألاباما</td>\n",
       "      <td>alabama_4_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>الألبانية</td>\n",
       "      <td>albanian_2_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>الأليوتية</td>\n",
       "      <td>aleut_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>الأمهرية</td>\n",
       "      <td>amharic_N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ar                en\n",
       "li                                   \n",
       "292            مطلق      absolute_3_A\n",
       "1168       إِدارِيّ  administrative_A\n",
       "1558      أفْغانِيّ       afghani_1_N\n",
       "1596  لغة أفريكانية       afrikaans_N\n",
       "1643           سِنّ           age_1_N\n",
       "1973       الأكانية            akan_N\n",
       "1987        ألاباما       alabama_4_N\n",
       "2019      الألبانية      albanian_2_N\n",
       "2085      الأليوتية           aleut_N\n",
       "2657       الأمهرية         amharic_N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ar_en_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Arabic words found in Words.gf: 479\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Arabic words found in Words.gf: {df_ar_en_words.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_en_words.to_csv(\"../results/ar2en_words_gf.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp(text: str):\n",
    "    w, ps = text.rsplit(\"_\", 1)\n",
    "    if w[-1].isdecimal():\n",
    "        ws, _ = w.rsplit(\"_\", 1)\n",
    "        return \" \".join(ws.split(\"_\"))\n",
    "    return \" \".join(w.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_en_words[\"en_\"] = df_ar_en_words[\"en\"].apply(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_en_words.to_csv(\"../results/ar2en_words_gf_.csv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thss-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
